#<?cfg paf policy ?>

# Main Image Simulator Policy File
# Created: June 16, 2010
# Author:  Nicole M. Silvestri, University of Washington
#	   gardnerj@phys.washington.edu
# Updated: Nov 30, 2011 - JPG
#
# Version: 2.0
# This configuration file is in Windows .ini format for use
#   with the Python ConfigParser class
#
# Note: You should copy/rename this file and edit it for your setup
#________________________________________________________

############################
## GENERAL PARAMETERS
############################

[general]
## JOB PARAMETERS

# Number of nodes per job
numNodes: 1

# Number of processors per job (eg: 1-8)
processors: 8

# Processor memory in MB
pmem: 1000

# Job name (eg: username on the cluster)
jobname: JeffsImSim

##
## DIRECTORY & PATH SETUP
##
# There are 3 main storage locations: 
#    1. On the submission node (i.e. the client node),
#    2. On a shared storage volume that is accessible from both the submit
#           and the execution nodes.
#    3. On the execution nodes.
#  The directory structure in each location is as follows:
#    
#     submission:
#        /"IMSIM_HOME_DIR"                # Absolute path to ImSim directory tree
#     shared:
#        /"stagingDir"                    # Abs. path to which files are staged before execution
#        /"stagingDir"/trimfiles          # Staging area for trimfiles
#        /"stagingDir"/*_fr.[pbs,csh]     # Staging of preprocessing scripts
#        /"stagingDir"/visitFiles*-fr.tar.gz # Staging of the per-visit files.
#        /"saveDir"                       # Abs. path to which output data is written

#        /"CAT_SHARE_DATA"/"dataTarball"  # Abs. path to the tarball containin catalog input data
#     execution:
#        /"scratchPath"                   # Abs. path to scratch directory on execution node
#        /"scratchPath"/"scratchDataDir"  # Path to the location of the untarred catalog data
#        /"scratchPath"/<scratchExecDir>  # Path to to ImSim directory tree on the exec node
#        /"scratchPath"/<scratchExecDir>/"scratchDataDir" # Path to output data on the exec node
#
#     <scratchExecDir> is determined at runtime and is the name of the work unit
#         (e.g. "1111110_R01_S00_E000fr")
#           

## Use the following two environment variables to define absolute paths:
#setenv IMSIM_HOME_DIR /share/home/nms/pt1.2imsimTrunk/
#setenv CAT_SHARE_DATA /share/pogo3/krughoff/shared/

# Absolute path to the directory where the final images/logs are to be written
# This path must be visible from both the submit and execution nodes.
# (Note, the files needed for each of the single-CCD runs are staged here after the
#  preprocessing runs).
saveDir: /share/lsstpoly/gardnerj/output

# Absolute path to the staging directory for the preprocessing run
# This path must be visible from both the submit and execution nodes.
stagingDir: /share/lsstpoly/gardnerj/staging

# Name of the tarball containing the input data (SEDS, QE, and height maps)
# in the client-side 'CAT_SHARE_DATA' directory.
dataTarball: data.tar.gz

# Absolute path for scratch partition where the jobs will be run.
# If this is being run in a cluster environment, this will be the
# directory on the remote nodes.
# (For PBS, the actual scratch directory will be 'scratchPath/$USER')
scratchPath: /state/partition1

# Name of temporary directory within the  to store images.
# This is also the location for the trimfiles for each run.
# Note: for PBS, this directory will be created in scratchPath/$USER
scratchOutputDir: simOutput

# Relative path from the scratch directory to the directory that has
# the SEDS, QE, and height maps
#datadir: data
scratchDataDir: data



## JOB MONITOR DATABASE

# Use the jobAllocator database (true or false)
# If "True" you will be required to enter lsst or exacycle-specific database params
# Note: Use "True" or "False" and note that these are case sensitive!
useDatabase: False

############################
## PBS-SPECIFIC PARAMETERS
############################

[pbs]
## PBS JOB PARAMS

# Cluster queue (eg: default, debug, scavenge, astro)
queue: default 

# Maximum time in hh:mm:ss that each job will run on the cluster (eg: 08:00:00)
walltime: 12:00:00

# Cluster user name 
username: gardnerj

# Root email address for notifications about cluster jobs (eg: @email_address)
rootEmail: @phys.washington.edu


## PBS JOB DIRECTORY & PATH SETUP

# JPG: Look like this is not actually used
# Tempoprary landing path for all files created for each imsim run (eg. parameter, fits files)
imsimRunDir: parFilesTemp

## SUBMIT (QSUB) SCRIPT SETUP

# Time in seconds for script to sleep between queue queries
sleep: 300

# Time in seconds to wait between successive job submissions to the cluster
wait: 2

# Maximum number of jobs allowed to be queued (running + idle) on the cluster
maxJobs: 10

############################
## LSST-SPECIFIC PARAMETERS
############################
## (These options require the LSST stack)

[lsst]
## JOB MONITOR DATABASE SETUP

# JobAllocator database table number (50-100)
tableId: 75

# sims/catalogs/generation location
catGen: /share/home/nms/catalogs_generation 
 
