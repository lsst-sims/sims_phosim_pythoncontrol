######################################################################
# Main Image Simulator Config File
#
# Please read the "CONFIGURATION FILES" section of README.txt
# for an explanation of this file.
#
# Note: You should copy/rename this file and edit it for your setup
######################################################################

############################
## GENERAL PARAMETERS
############################

[general]

##
## PYTHON SETUP
##

# We require at least Python 2.5.  Since 2.4 is the default on many systems,
# include the name/location of a Python 2.5 or greater.  This will be
# called during the preprocessing stage to execute "fullFocalPlane.py"
# and "chip.py"
python-exec: python26

##
## SCHEDULER SELECTION
##

# It is possible to use different schedulers for different processing
# phases.  For example, one can select "csh" to generate a regular
# shell script for the pre-processing, but then have this generate
# a set of PBS batch jobs.

# The scheduler used for the pre-processing phase:
#    csh, pbs, or exacycle
scheduler1: csh

# The scheduler used for the per-chip phase (raytracing and beyond):
#    csh, pbs, or exacycle
scheduler2: csh

##
## JOB PARAMETERS
##

# Number of nodes per job (Ignored in csh)
numNodes: 1

# Number of processors per job (eg: 1-8, Ignored in csh)
processors: 1

# Processor memory in MB (Ignored in csh)
pmem: 1000

# Job name (Ignored in csh)
jobname: JeffsImSim

# Jobs can optionally sleep for a random number of seconds between
# 0 and 'sleepmax' upon startup.  This prevents jobs starting at the exact
# same time on a specific execution node and thus stepping on top of
# one another when they are trying to determine if the scratchDataDir
# is already present and intact.
# Setting sleepmax to '60' on Minerva yields good results.
# Setting sleepmax to '0' will disable this feature.
sleepmax: 0

# The level of debugging information ('0'=none, '1' adds '-x' to shell scripts)
debuglevel: 1

##
## DIRECTORY & PATH SETUP
##

# The directory and path setup is explained in detail in README.txt

##
## Shared input datasets:
## ----------------------

# The shared input data is divided into two parts.  The first set contains the
# data needed for the preprocessing stage (QE and height maps).  The
# second set contains the SEDs needed for the raytracing stage.
#
#!!!!!!!!!!!!!!!!
# IMPORTANT NOTE: Unlike with the "full_focalplane" shell script, the data
#!!!!!!!!!!!!!!!! tarballs used here should *not* contain "data" as the root
#                 directory (this just made things too complicated in the script
#                 logic).  For example, the directories "focal_plane," agnSED," starSED,"
#                 etc should be in the root of the tarball.
#
# In the case of the either dataset, the tarball
# is copied from shared storage to scratchSharedPath and untarred
# UNLESS useSharedFP or useSharedSEDs is set to "true".  In
# this case, the data will be read directly from shared storage instead.
# Note that to read directly from shared storage, it must be from
# a filesystem that supports symbolic links.

# true:  Read preprocessing shared data directly from shared storage location
# false: Copy the dataTarballFP to local storage ("scratchDataPath") and untar
useSharedFP: true

# If useSharedFP is "true":  Ignore this parameter
# If useSharedFP is "false": Name of "FP" data tarball to copy to "scratchDataPath"
dataTarballFP: dataFP.tar

# Path to shared "FP" data.  This will either be
# If useSharedFP is "true":  The path that contains the focal_plane directory
# If useSharedFP is "false": The path that contains the shared data tarball
#                             "<dataTarballFP> (i.e. "<dataPathFP>"/"<dataTarballFP>")
dataPathFP: /scratch/gardnerj/lsst/data_focal_plane_06112012

# true:  Read preprocessing shared data directly from shared storage location
# false: Copy the dataTarballSEDs to local storage ("scratchDataPath") and untar
useSharedSEDs: true

# If useSharedSEDs is "true":  Ignore this parameter
# If useSharedSEDs is "false": Name of "PRE" data tarball to copy to "scratchDataPath"
dataTarballSEDs: dataSEDs.tar

# Path to shared "SEDs" data.  This will either be
# If useSharedSEDs is "true":  The path that contains the focal_plane and *SED directories
# If useSharedSEDs is "false": The path that contains the shared data tarball "<dataTarballSEDs>"
#                              (i.e. "<dataPathSEDs>/<dataTarballSEDs>")
dataPathSEDs: /scratch/gardnerj/lsst/data_seds_06112012

# Absolute path on the execution node to which the shared data will be staged.
# This should be different from scratchExecPath or else the shared data will
# be deleted from the exec node upon completion of this work unit. 
# The resulting untarred data will be stored in "scratchDataPath/sharedData".
# If useShared[PRE,SEDs] is set to "true" this is ignored (since no data is staged)
scratchDataPath: /scratch/gardnerj/lsst/scratch/sharedData


##
## Paths for work-specific data and parameter files
##

# Absolute path to the staging directory for the preprocessing stage
# This path must be visible from both the submit and execution nodes.
stagePath1: /scratch/gardnerj/lsst/shared/staging1

# Absolute path to the staging directory for the raytracing stage.
# This path must be visible from the execution nodes that run the
# preprocessing stage and execution nodes that run the raytracing stage.
# (Note: this can be set to the same location as stagePath1 if desired)
stagePath2: /scratch/gardnerj/lsst/shared/staging2

# Absolute path to the directory where the final images/logs are to be written
# This path must be visible from both the submit and execution nodes.
# (Note: This can be set to the same location as either or both of
#  the stagePaths if desired)
savePath: /scratch/gardnerj/lsst/shared/output

# Absolute path for scratch partition where the jobs will be run.
# If this is being run in a cluster environment, this will be the
# directory on the remote nodes.
# (For Minerva and other HPC systems, this should include one's username)
scratchExecPath: /scratch/gardnerj/lsst/scratch/exec

# Name of temporary directory within /"scratchExecPath"/<workunitID>
# to store images. This is also the location for the trimfiles for each run.
scratchOutputDir: simOutput



## JOB MONITOR DATABASE

# Use the jobAllocator database (true or false)
# If "True" you will be required to enter lsst or exacycle-specific database params
# Note: Use "True" or "False" and note that these are case sensitive!
useDatabase: False


############################
## LSST-SPECIFIC PARAMETERS
############################
## (These options require the LSST stack)

[lsst]
## JOB MONITOR DATABASE SETUP

# JobAllocator database table number (50-100)
tableId: 75

# sims/catalogs/generation location
catGen: /share/home/nms/catalogs_generation 
 
